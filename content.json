{"meta":{"title":"My Page","subtitle":"test subtitle","description":"test description","author":"Xiaohao Yan","url":"http://yan-code1.github","root":"/"},"pages":[{"title":"about","date":"2020-02-12T14:14:36.000Z","updated":"2022-03-24T15:32:21.591Z","comments":false,"path":"about/index.html","permalink":"http://yan-code1.github/about/index.html","excerpt":"","text":"颜晓豪 15872133751 · yanxiaohaos@163.com · yan-code1 · My Blog 个人信息 男，1998.9月出生 教育经历 硕士，厦门大学，通信工程专业，2020.9~2023.6 学士，武汉理工大学，通信工程专业，2016.9~2020.6 通过了 CET4/6 英语等级考试 计算机网络三级证书 华为杯研究生数学建模全国一等奖 兆易创新杯研究生电赛技术三等奖 项目经历 树莓派小车中控平台项目 简介：本项目主要构建一个由中控平台和树莓派小车终端组成的群体智能平台，通过强化学习来训练树莓派小车的视频传输和通信抗干扰决策，目的是为了降低传输时延，丢包率。 职务：负责中控平台与树莓派小车的视频传输传输框架，主要基于TCP/UDP协议，以及多线程和多进程的调度，并在特定场景下使用强化学习算法对传输决策进行训练。 技能清单 ★★★ Python、Java ★★☆ AI算法、算法和数据结构 ★★☆ 计算机网络、网络编程"},{"title":"conmment","date":"2022-03-13T08:58:41.000Z","updated":"2022-03-13T08:58:41.351Z","comments":true,"path":"comment/index.html","permalink":"http://yan-code1.github/comment/index.html","excerpt":"","text":""},{"title":"links","date":"2022-03-13T08:59:17.000Z","updated":"2022-03-13T08:59:17.584Z","comments":true,"path":"links/index.html","permalink":"http://yan-code1.github/links/index.html","excerpt":"","text":""},{"title":"tags","date":"2022-03-13T08:57:22.000Z","updated":"2022-03-13T08:57:22.949Z","comments":true,"path":"tags/index.html","permalink":"http://yan-code1.github/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"基于UDP的socket多播传输","slug":"UDP_Transmission","date":"2022-03-07T06:54:29.170Z","updated":"2022-03-07T07:02:38.559Z","comments":true,"path":"2022/03/07/UDP_Transmission/","link":"","permalink":"http://yan-code1.github/2022/03/07/UDP_Transmission/","excerpt":"","text":"项目网址：https://github.com/yan-code1/UDP_Transmission组播部分组播发送的数据包只能在同一网络下进行，比如同一路由器、多个交换机组成的单个网络或者路由器桥接组成的单个网络，否则经过两跳后数据将接收不到需要注意的是： 参数注意： MCAST_GRP 和 MCAST_PORT代表组播地址和组播端口，与本地端口和本地IP没半毛钱关系 MULTICAST_TTL参数代表 设置多播组数据的TTL值，范围为0～255之间的任何值； IP_ADD_MEMBERSHIP 代表在指定接口上加入组播组 组播地址范围注意： 224.0.0.0～224.0.0.255为预留的组播地址（永久组地址），地址224.0.0.0保留不做分配，其它地址供路由协议使用。 224.0.1.0～238.255.255.255为用户可用的组播地址（临时组地址），全网范围内有效。 239.0.0.0～239.255.255.255为本地管理组播地址，仅在特定的本地范围内有效。 计算MD5添加唯一标识mreq = struct.pack(\"4sl\", socket.inet_aton(MCAST_GRP), socket.INADDR_ANY) sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)","categories":[],"tags":[]},{"title":"在github上搭建hexo博客主页","slug":"create_web_page","date":"2022-03-04T08:54:02.994Z","updated":"2022-03-07T06:50:12.938Z","comments":true,"path":"2022/03/04/create_web_page/","link":"","permalink":"http://yan-code1.github/2022/03/04/create_web_page/","excerpt":"","text":"这里只介绍win10平台的搭建流程1.搭建前的配置： Github账号 安装Git 下载安装Nodejs和npm，通过 node -v 和 npm -v 命令检查是否安装。2. 为nodejs文件夹配置环境变量（貌似其实用处也不大）3.安装hexo 打开git brashnpm install -g hexo 通过hexo -v命令即可检查是否安装成功，据说好像要将hexo的bin目录加到环境变量，但我不加也没出现问题。 4. 本地搭建 新建文件夹Blog（可自定义），然后在该文件夹下进入git brash,执行：hexo init # 下载hexo默认主题 hexo s --debug -p 8888 # 即可在local:8888查看博客 5.GitHub ssh key配置 配置全局用户以免每次输入密码,yourname 和 youremail分别指你的github用户名以及github绑定的邮箱git config --global user.name yourname git config --global user.email youremail 生成秘钥和公钥ssh -keygen -t rsa -C \"youremail\" # 执行了这个命令会提示存储路径和密码以及确认密码：你连续按三次Enter就好 到用户文件夹下/.ssh/打开id_rsa.pub文件，即为公钥文件,等会新建github ssh key要用。 进入github主页，点击右边的设置进入ssh and GPG keys, 新建ssh key 复制刚才的公钥到key ,title随便写。 完成后执行ssh -T git@github.com 出现Hi xxx! You’ve successfully authenticated, but GitHub does not provide shell access.6.部署到github 到github主页新建仓库 username.github.io , username 为你的账户名 修改Blog配置文件__config.yml,打开拉到最底下，修改最后两行为如下，repo为仓库的ssh地址deploy: type: git repo: git@github.com:username/username.github.io.git 最后进行部署```hexo cleanhexo ghexo d 若执行hexo d有错误：ERROR Deployer not found: git则执行：npm install –save hexo-deployer-git + 访问：直接访问username.github.io即可","categories":[],"tags":[]},{"title":"TCP学习笔记","slug":"TCP_notes","date":"2021-12-05T03:22:00.000Z","updated":"2022-03-15T05:19:09.857Z","comments":true,"path":"2021/12/05/TCP_notes/","link":"","permalink":"http://yan-code1.github/2021/12/05/TCP_notes/","excerpt":"","text":"TCP协议所处位置——传输层 在传输层细分 本节内容大纲 概念和比较 TCP结构和详解 可靠传输：序号，确认，重传，冗余 传输控制：流量控制，拥塞控制 潜在的问题 疑问 1 概念和比较1. 1 TCP和UDP的简单区别 TCP面向连接，是一个全双工的可靠信道 UDP无连接，是一个不可靠信道 1.2 TCP的流程： 建立连接——3次握手 1.Client发起连接请求,并初始化序列号：SYN = 1 seq = J。Client进入SYN_SENT状态，等待Server确认。2.Server确认连接请求：ACK = 1 SYN = 1 seq = K ack = J+1。Server进入SYN_RCVD状态3.Client收到确认后，检查接受报文中ack是否为J+1，ACK是否为1，发送报文：ACK=1,seq = J+1,ack = K+1。 Server检查ack是否为K+1，ACK是否为1。如果正确则连接建立成功，Client和Server进入ESTABLISHED状态 提问： 为什么TCP客户端最后还要发送一次确认呢？ 答: 防止已经失效的连接请求报文突然又传送到了服务器 tcp三次握手报文能携带数据吗？ 答：前两次握手不能携带数据（SYN = 1的报文），第三次握手允许携带数据，若不携带数据则不消耗序列号。一般是不携带数据。释放连接——4次挥手 （1）第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。（2）第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态。（3）第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。（4）第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1，Server进入CLOSED状态，完成四次挥手。 注意： 四次挥手时，通信双方谁先发起连接中断请求谁就是客户端。 收到对方的FIN报文时，表示对方不再发送数据了，但是我自己还可以发送。 通常一方发起FIN报文后，另一方无论在什么情况下都应该立即回应ACK报文，特殊情况下还会有下面的同时发起FIN的情况。 所以挥手就只是发FIN和立即收ACK的一个过程，只是双方各执行了一遍。 提问： 为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？ 答：双方连接的释放可能不同步。收到对方的FIN报文，仅仅表示对方没有数据发送给你，但你的数据未必发完了。 为什么TIME_WAIT状态还需要等2MSL后才能返回到CLOSED状态？ 答：TIME_WAIT的作用就是重发可能丢失的ACK报文，因为网络不一定可靠。 2 TCP结构和详解2.1 TCP的结构 其中控制位包括6个，分别是URG，ACK ,PSH,RSTSYN,FIN ACK：表示前面的确认号字段是否有效。1为有效。规定连接建立后ACK必须为1； SYN：同步序列号，连接建立时才会使用。只有在前两次握手中SYN才置为1，如连接请求报文段ACK = 0，SYN = 1 ，同意建立连接ACK = 1，SYN = 1； FIN :标记数据是否发送完毕。FIN=1表示发送完毕，告诉对方可以释放连接了； URG：紧急数据。URG=1表示含紧急数据。 RSH：数据是缓存还是直接推送给上层。RSH=1表示直接提交。 RST ：连接错误，需要释放连接。RST=时表示错误。 注意Acknowledgment Number≠ACK,前者是确认应答号，32位；后者为控制位，1位。3 可靠传输 序号：让数据有序 确认：好，我收到了，请继续 重传：很长时间没收到回信，重发一份 冗余：反复提醒，直到不耐烦为止 3.1确认机制 发送编码和打包（注意这里是不断进行发送，而不是传完一个才传下一个） 发送方会将源文件按一个字节一个字节进行编号1，2，…,然后发送端要进行数据发送时，将几个编号的字节打包成一个报文，报文的编号为要发送的第一个字节的编号如:1,2,3,4组成的报文段，其编号为1。 接受和继续发送请求 接受端收到报文后记录最后一个字节的编号4，然后将编号加一发送，以请求接下来的数据，如4+1=5，继续发送5，6报文段。 发送端确认报文接受并释放，。如释放报文1，2，3，4；发送5，6，7报文。 一种特殊情况：由于发送方是不断传，可能5报文还没到，7报文就已经到了，但此时接收端不发送7+1=8请求 3.2重传机制TCP的重传主要分为两类：定时重传和快速重传。3.2.1定时重传 定时重传是指发送数据时设置一个定时器，如果超过指定的时间后没有收到确认应答报文ACK就会重发该数据。 4 潜在的问题 粘包问题 传输效率低 5 疑问 每个字节都会编号，那一旦文件大小超过最大数字怎么办？ 答：序列号由32位表示，每2^32个字节，序列号会重新从0开始。 如何区分两个不同报文段的相同序列号？","categories":[],"tags":[]},{"title":"nginx流媒体服务器搭建","slug":"nginx","date":"2021-07-22T19:46:00.000Z","updated":"2022-03-24T15:22:36.780Z","comments":true,"path":"2021/07/23/nginx/","link":"","permalink":"http://yan-code1.github/2021/07/23/nginx/","excerpt":"","text":"一、nginx服务器搭建1.安装nginx并配置http://nginx-win.ecsds.eu/download/下载nginx 1.7.11.3 Gryphon.zip该版本的nginx包含rtmp组件。 2.解压后在该目录下打开cmd,输入ngxin -v 出现版本号即安装成功。3.在nginx 1.7.11.3 Gryphon目录下新建三个目录：m3u8File、rec、vod，如下图所示： 4.配置conf/ngxin.conf文件，改为如下：worker_processes 1; #Nginx进程数，建议设置为等于CPU总核数 events { worker_connections 1024; #工作模式与连接数上限 } rtmp_auto_push on; #RTMP服务 rtmp{ server{ listen 1935; #服务端口 chunk_size 4096; #数据传输块的大小 application vod{ play ./vod; #视频文件存放位置 } application live{ live on; #开启直播 hls on; #开启hls直播。这个参数把直播服务器改造成实时回放服务器 #wait_key on; #对视频切片进行保护，这样就不会产生马赛克了 hls_path ./m3u8File; #切片视频文件存放位置（HLS，m3u8文件存放位置） hls_fragment 2s; #每个视频切片的时长 hls_playlist_length 16s; recorder myRecord{ record all manual; record_suffix _.flv; record_path ./rec; } #hls_continuous on; #连续模式 #hls_cleanup on; #对多余的切片进行删除 #hls_nested on; #嵌套模式 } } } #HTTP服务 http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 80; server_name localhost; location / { root html; index index.html index.htm; } location /live_hls{ types{ #m3u8 type设置 application/vnd.apple.mpegurl m3u8; #ts分片文件设置 video/mp2t ts; } #指向访问m3u8文件目录 alias ./m3u8File; add_header Cache-Control no-cache; #禁止缓存 } location /control{ rtmp_control all; } location /stat{ rtmp_stat all; rtmp_stat_stylesheet stat.xsl; } location /stat.xsl{ root ./nginx-rtmp-module-master; } # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } 5.输入nginx.exe -t检查配置文件是否正确6.start nginx 启动服务7.浏览器输入主机ip或localhost或者127.0.0.1得到以下界面说明配置成功，用户可以通过命令nginx.exe -s stop或者nginx.exe -s quit停止nginx。 二、推拉流1.下载ffmpeg工具包2.通过指令可将MP4文件转化成rtmp流到live。ffmpeg -i video3.mp4 -f flv rtmp://127.0.0.1/live/test1 若需要测试可以改成循环推流-stream_loop -1 -1代表无限循环 3.拉流也可以通过opencv直接输入rtmp地址三、最无脑的流媒体服务器部署支持win10和ubuntu平台：rtmpd","categories":[],"tags":[]},{"title":"ffmpeg推流指令","slug":"ffmpeg","date":"2021-07-21T01:16:00.000Z","updated":"2022-03-24T15:15:22.122Z","comments":true,"path":"2021/07/21/ffmpeg/","link":"","permalink":"http://yan-code1.github/2021/07/21/ffmpeg/","excerpt":"","text":"堆叠推流方法： import ffmpeg in_file = ffmpeg.input('input.mp4') overlay_file = ffmpeg.input('overlay.png') ( ffmpeg .concat( in_file.trim(start_frame=10, end_frame=20), in_file.trim(start_frame=30, end_frame=40), ) .overlay(overlay_file.hflip()) .drawbox(50, 50, 120, 120, color='red', thickness=5) .output('out.mp4') .run() ) 一次推多个视频的方式 ffmpeg -re -i \"concat:1.mp4|2.mp4\" -c:a aac -c:v copy -f flv rtmp://127.0.0.1:1935/live/test # ffmpeg -v verbose -f concat -safe 0 -protocol_whitelist file,http,tcp -re -i 1.txt -c:a aac -c:v h264 -f flv rtmp://127.0.0.1:1935/live/test # 来自 &lt;https://mengkang.net/1453.html&gt; 推摄像头,仅当设备名为/dev/video0时，针对linux平台 ffmpeg -i /dev/video0 -vcodec h264_omx -acodec copy -preset:v ultrafast -tune:v zerolatency -f flv \"推流地址 直接调用摄像头的推流命令(针对win10平台) ffmpeg -f dshow -i video=\"Integrated Camera\" -vcodec libx264 -preset:v ultrafast -tune:v zerolatency -r 25 -pix_fmt yuv420p -s \"640x480\" -f flv rtmp://127.0.0.1:1935/live/stream # ffmpeg -f dshow -i video=\"Integrated Camera\" -vcodec libx264 rtmp://127.0.0.1:1935/live/test # ffmpeg -f dshow -i video=\"Integrated Camera\" -vcodec libx264 -preset:v ultrafast -tune:v zerolatency -f flv rtmp://127.0.0.1:1935/live/test","categories":[],"tags":[]},{"title":"调用google speech recognition实现语音片段识别","slug":"google-speech","date":"2020-02-03T09:27:00.000Z","updated":"2022-03-13T09:28:20.235Z","comments":true,"path":"2020/02/03/google-speech/","link":"","permalink":"http://yan-code1.github/2020/02/03/google-speech/","excerpt":"","text":"代码位置：环境配置：win10 安装PyAudio ,高版本python直接pip会报错，可能需要用源码安装，这里提供3.7的源码:pypi.python.org/pypi/PyAudio https://github.com/intxcc/pyaudio_portaudio/releases pip install SpeechRecognition谷歌语音识别库，需要联网 需要注意的是 该识别仅支持音频格式为.wav，有需要可以利用ffmpeg进行格式转换： ** ffmpeg -i test.m4s out.wav ** 仅支持片段识别，时间过长会导致请求失败，需要添加切片的功能 有两种调用方式，一种是直接读取语音文件，第二种是读取麦克风 函数进行识别语音范围指定（按时长），duration为终点，offset为起点；record(source,duration=None,offset=None) recognize_google(audioFile,language =’en-US’)语言选择en-US,zh-CN import speech_recognition as sr import os r = sr.Recognizer() # use microphone # with sr.Microphone() as source: # print(\"Say something!\") # audio = r.listen(source) # use audio file file_path = 'ts/1.wav' audioFile = sr.AudioFile(file_path) with audioFile as source: audio = r.record(source) # r.recognize_sphinx(audio, language='zh_CN') # 选择语言 # 选择翻译片段 try: text = r.recognize_google(audio) print(\"You said: \" + text) except sr.UnknownValueError: print(\"Google Speech Recognition could not understand audio\") except sr.RequestError as e: print(\"Could not request results from Google Speech Recognition service\" + format(e)) 利用多线程实现了批量快速识别： https://github.com/yan-code1/TrainingCode/blob/main/TrainCode/someTools/AudioVideoProcess/audioRecGoogle.py","categories":[],"tags":[]},{"title":"爬取网页视频-.m3u8格式","slug":"catch","date":"2020-02-02T02:21:00.000Z","updated":"2022-03-25T03:43:21.664Z","comments":true,"path":"2020/02/02/catch/","link":"","permalink":"http://yan-code1.github/2020/02/02/catch/","excerpt":"","text":"注：仅针对可直接获取.m3u8文件并解析其中的’.m4s’ 或者’.ts’文件的流视频。本人仅因为论文研究便利而开发使用，使用网址为：https://papertalk.org/index，可爬取你想要的论文讲解视频，本人还开发了后续的语音分割和调用google speech进行翻译得到字幕。代码逻辑如下： 1.解析各分片的url并保存 2.利用url进行分片文件的下载和保存 3.将分片合并，然后转换成.mp4文件 1.通过浏览器到视频网页抓取必要信息 主要爬取header 信息和base url信息，分别用于进行请求和视频地址解析后的下载2. 解析各分片的url并保存爬取的m3u8文件解读#EXTM3U #EXT-X-VERSION:6 #EXT-X-TARGETDURATION:4 #EXT-X-MEDIA-SEQUENCE:1 #EXT-X-MAP:URI=\"init_0_2500000.m4s\" #EXTINF:4.000000, #EXT-X-PROGRAM-DATE-TIME:2021-07-10T17:36:55.000+0000 chunk_0_2500000_00001.m4s #EXTINF:4.000000, #EXT-X-PROGRAM-DATE-TIME:2021-07-10T17:36:59.000+0000 chunk_0_2500000_00002.m4s #EXTINF:4.000000, #EXT-X-PROGRAM-DATE-TIME:2021-07-10T17:37:03.000+0000 chunk_0_2500000_00003.m4s #EXTINF:4.000000, #EXT-X-PROGRAM-DATE-TIME:2021-07-10T17:37:07.000+0000 chunk_0_2500000_00004.m4s 注意这个init文件一定要下下来，要不然转格式的时候会报错:[mov,mp4,m4a,3gp,3g2,mj2 @ 0000024d01bbdf40] could not find corresponding track id 1 [mov,mp4,m4a,3gp,3g2,mj2 @ 0000024d01bbdf40] could not find corresponding trex (id 1) [mov,mp4,m4a,3gp,3g2,mj2 @ 0000024d01bbdf40] could not find corresponding track id 0 [mov,mp4,m4a,3gp,3g2,mj2 @ 0000024d01bbdf40] trun track id unknown, no tfhd was found [mov,mp4,m4a,3gp,3g2,mj2 @ 0000024d01bbdf40] error reading header ./10.m4s: Invalid data found when processing input 然后通过文件流将块按顺序合并为一个文件：out.m4s最后利用ffmpeg -i ‘./out.m4s’ -c copy ‘out.mp4’将格式转为mp4即可 单线程稳定版项目地址为：https://github.com/yan-code1/TrainingCode/blob/main/TrainCode/someTools/AudioVideoProcess/m3u8SingleCatch.py多线程快速下载版为：https://github.com/yan-code1/TrainingCode/blob/main/TrainCode/someTools/AudioVideoProcess/m3u8_video_audio_catch.py 仅需下载网站对应.m3u8文件，然后修改代码中文件名,header，url即可","categories":[],"tags":[]}],"categories":[],"tags":[]}